{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import time\n",
    "import math\n",
    "from matplotlib import pyplot\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from pandas import read_csv\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_loss_over_all_values = False\n",
    "input_window = 100\n",
    "output_window = 5\n",
    "batch_size = 10\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super(PositionalEncoding, self).__init__()       \n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
    "        \n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:x.size(0), :]\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TransAm(nn.Module):\n",
    "    def __init__(self,feature_size=250,num_layers=1,dropout=0.1):\n",
    "        super(TransAm, self).__init__()\n",
    "        self.model_type = 'Transformer'\n",
    "        \n",
    "        self.src_mask = None\n",
    "        self.pos_encoder = PositionalEncoding(feature_size)\n",
    "        self.encoder_layer = nn.TransformerEncoderLayer(d_model=feature_size, nhead=10, dropout=dropout)\n",
    "        self.transformer_encoder = nn.TransformerEncoder(self.encoder_layer, num_layers=num_layers)        \n",
    "        self.decoder = nn.Linear(feature_size,1)\n",
    "        self.init_weights()\n",
    "\n",
    "    def init_weights(self):\n",
    "        initrange = 0.1    \n",
    "        self.decoder.bias.data.zero_()\n",
    "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    "\n",
    "    def forward(self,src):\n",
    "        if self.src_mask is None or self.src_mask.size(0) != len(src):\n",
    "            device = src.device\n",
    "            mask = self._generate_square_subsequent_mask(len(src)).to(device)\n",
    "            self.src_mask = mask\n",
    "\n",
    "        src = self.pos_encoder(src)\n",
    "        output = self.transformer_encoder(src,self.src_mask)\n",
    "        output = self.decoder(output)\n",
    "        return output\n",
    "\n",
    "    def _generate_square_subsequent_mask(self, sz):\n",
    "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
    "        mask = mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))\n",
    "        return mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_input_sequences(input_data, tw):\n",
    "    input_seq = []\n",
    "    L = len(input_data)\n",
    "    for i in range(L-tw):\n",
    "        train_seq = np.append(input_data[i:i+tw][:-output_window] , output_window * [0])\n",
    "        train_label = input_data[i:i+tw]\n",
    "        input_seq.append((train_seq ,train_label))\n",
    "    return torch.FloatTensor(input_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./dataset/merged.csv\")\n",
    "df = torch.Tensor(df.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([40178, 6])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_data():\n",
    "    time        = np.arange(0, 400, 0.1)\n",
    "    amplitude   = np.sin(time) + np.sin(time*0.05) +np.sin(time*0.12) *np.random.normal(-0.2, 0.2, len(time))\n",
    "    \n",
    "    series = read_csv('/home/arty/Desktop/NYU Spring 2022/6DOF/dataset/test.csv', header=0, index_col=0, parse_dates=False, squeeze=True)\n",
    "    \n",
    "    from sklearn.preprocessing import MinMaxScaler\n",
    "    scaler = MinMaxScaler(feature_range=(-1, 1)) \n",
    "    amplitude = scaler.fit_transform(series.to_numpy().reshape(-1, 1)).reshape(-1)\n",
    "\n",
    "    \n",
    "    sampels = 2800\n",
    "    train_data = amplitude[:sampels]\n",
    "    test_data = amplitude[sampels:]\n",
    "    train_sequence = create_input_sequences(train_data,input_window)\n",
    "    train_sequence = train_sequence[:-output_window] \n",
    "\n",
    "    test_data = create_input_sequences(test_data,input_window)\n",
    "    test_data = test_data[:-output_window] \n",
    "\n",
    "    return train_sequence.to(device),test_data.to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(source, i,batch_size):\n",
    "    seq_len = min(batch_size, len(source) - 1 - i)\n",
    "    data = source[i:i+seq_len]    \n",
    "    input = torch.stack(torch.stack([item[0] for item in data]).chunk(input_window,1)) \n",
    "    target = torch.stack(torch.stack([item[1] for item in data]).chunk(input_window,1))\n",
    "    return input, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_data):\n",
    "    model.train()\n",
    "    total_loss = 0.\n",
    "    start_time = time.time()\n",
    "\n",
    "    for batch, i in enumerate(range(0, len(train_data) - 1, batch_size)):\n",
    "        data, targets = get_batch(train_data, i,batch_size)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)        \n",
    "\n",
    "        if calculate_loss_over_all_values:\n",
    "            loss = criterion(output, targets)\n",
    "        else:\n",
    "            loss = criterion(output[-output_window:], targets[-output_window:])\n",
    "    \n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5)\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        log_interval = int(len(train_data) / batch_size / 5)\n",
    "        if batch % log_interval == 0 and batch > 0:\n",
    "            cur_loss = total_loss / log_interval\n",
    "            elapsed = time.time() - start_time\n",
    "            print('| epoch {:3d} | {:5d}/{:5d} batches | '\n",
    "                  'lr {:02.6f} | {:5.2f} ms | '\n",
    "                  'loss {:5.5f} | ppl {:8.2f}'.format(\n",
    "                    epoch, batch, len(train_data) // batch_size, scheduler.get_lr()[0],\n",
    "                    elapsed * 1000 / log_interval,\n",
    "                    cur_loss, math.exp(cur_loss)))\n",
    "            total_loss = 0\n",
    "            start_time = time.time()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_and_loss(eval_model, data_source,epoch):\n",
    "    eval_model.eval() \n",
    "    total_loss = 0.\n",
    "    test_result = torch.Tensor(0)    \n",
    "    truth = torch.Tensor(0)\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(data_source) - 1):\n",
    "            data, target = get_batch(data_source, i,1)\n",
    "            output = eval_model(data)    \n",
    "            if calculate_loss_over_all_values:                                \n",
    "                total_loss += criterion(output, target).item()\n",
    "            else:\n",
    "                total_loss += criterion(output[-output_window:], target[-output_window:]).item()\n",
    "            \n",
    "            test_result = torch.cat((test_result, output[-1].view(-1).cpu()), 0) \n",
    "            truth = torch.cat((truth, target[-1].view(-1).cpu()), 0)\n",
    "            # print(test_result.shape, test_data)\n",
    "            # print(truth.shape, truth)\n",
    "    len(test_result)\n",
    "\n",
    "    # pyplot.plot(test_result,color=\"red\")\n",
    "    pyplot.plot(truth[:500],color=\"blue\")\n",
    "    pyplot.plot(test_result-truth,color=\"green\")\n",
    "    pyplot.grid(True, which='both')\n",
    "    # pyplot.axhline(y=0, color='k')\n",
    "    pyplot.savefig('graph/transformer-epoch%d.png'%epoch)\n",
    "    pyplot.close()\n",
    "    \n",
    "    return total_loss / i\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_future(eval_model, data_source,steps):\n",
    "    eval_model.eval() \n",
    "    total_loss = 0.\n",
    "    test_result = torch.Tensor(0)    \n",
    "    truth = torch.Tensor(0)\n",
    "    _ , data = get_batch(data_source, 0,1)\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, steps,1):\n",
    "            input = torch.clone(data[-input_window:])\n",
    "            input[-output_window:] = 0     \n",
    "            output = eval_model(data[-input_window:])                        \n",
    "            data = torch.cat((data, output[-1:]))\n",
    "            \n",
    "    data = data.cpu().view(-1)\n",
    "    \n",
    "\n",
    "    # pyplot.plot(data,color=\"red\")       \n",
    "    pyplot.plot(data[:input_window],color=\"blue\")\n",
    "    pyplot.grid(True, which='both')\n",
    "    # pyplot.axhline(y=0, color='k')\n",
    "    pyplot.savefig('graph/transformer-future%d.png'%steps)\n",
    "    pyplot.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:30: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:30: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "/tmp/ipykernel_14839/560967404.py:30: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if(epoch % 10 is 0):\n",
      "/home/arty/anaconda3/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   1 |    53/  269 batches | lr 0.005000 |  4.27 ms | loss 6.67228 | ppl   790.19\n",
      "| epoch   1 |   106/  269 batches | lr 0.005000 |  4.04 ms | loss 0.02530 | ppl     1.03\n",
      "| epoch   1 |   159/  269 batches | lr 0.005000 |  4.34 ms | loss 0.00727 | ppl     1.01\n",
      "| epoch   1 |   212/  269 batches | lr 0.005000 |  3.66 ms | loss 0.05185 | ppl     1.05\n",
      "| epoch   1 |   265/  269 batches | lr 0.005000 |  3.67 ms | loss 0.04056 | ppl     1.04\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   1 | time:  1.63s | valid loss 0.35422 | valid ppl     1.43\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   2 |    53/  269 batches | lr 0.004802 |  3.78 ms | loss 0.04052 | ppl     1.04\n",
      "| epoch   2 |   106/  269 batches | lr 0.004802 |  3.83 ms | loss 0.01932 | ppl     1.02\n",
      "| epoch   2 |   159/  269 batches | lr 0.004802 |  4.69 ms | loss 0.01472 | ppl     1.01\n",
      "| epoch   2 |   212/  269 batches | lr 0.004802 |  6.03 ms | loss 0.03104 | ppl     1.03\n",
      "| epoch   2 |   265/  269 batches | lr 0.004802 |  4.49 ms | loss 0.04652 | ppl     1.05\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   2 | time:  1.78s | valid loss 0.22230 | valid ppl     1.25\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   3 |    53/  269 batches | lr 0.004706 |  3.80 ms | loss 0.03630 | ppl     1.04\n",
      "| epoch   3 |   106/  269 batches | lr 0.004706 |  3.62 ms | loss 0.02364 | ppl     1.02\n",
      "| epoch   3 |   159/  269 batches | lr 0.004706 |  3.69 ms | loss 0.00274 | ppl     1.00\n",
      "| epoch   3 |   212/  269 batches | lr 0.004706 |  3.62 ms | loss 0.02852 | ppl     1.03\n",
      "| epoch   3 |   265/  269 batches | lr 0.004706 |  3.74 ms | loss 0.05897 | ppl     1.06\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   3 | time:  1.54s | valid loss 0.21678 | valid ppl     1.24\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   4 |    53/  269 batches | lr 0.004612 |  3.74 ms | loss 0.01964 | ppl     1.02\n",
      "| epoch   4 |   106/  269 batches | lr 0.004612 |  3.69 ms | loss 0.02377 | ppl     1.02\n",
      "| epoch   4 |   159/  269 batches | lr 0.004612 |  3.61 ms | loss 0.02572 | ppl     1.03\n",
      "| epoch   4 |   212/  269 batches | lr 0.004612 |  3.68 ms | loss 0.03529 | ppl     1.04\n",
      "| epoch   4 |   265/  269 batches | lr 0.004612 |  3.65 ms | loss 0.06469 | ppl     1.07\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   4 | time:  1.54s | valid loss 0.26789 | valid ppl     1.31\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   5 |    53/  269 batches | lr 0.004520 |  3.77 ms | loss 0.01830 | ppl     1.02\n",
      "| epoch   5 |   106/  269 batches | lr 0.004520 |  3.62 ms | loss 0.04661 | ppl     1.05\n",
      "| epoch   5 |   159/  269 batches | lr 0.004520 |  3.62 ms | loss 0.03873 | ppl     1.04\n",
      "| epoch   5 |   212/  269 batches | lr 0.004520 |  3.63 ms | loss 0.01918 | ppl     1.02\n",
      "| epoch   5 |   265/  269 batches | lr 0.004520 |  3.62 ms | loss 0.06491 | ppl     1.07\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   5 | time:  1.53s | valid loss 0.23284 | valid ppl     1.26\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   6 |    53/  269 batches | lr 0.004429 |  3.74 ms | loss 0.01621 | ppl     1.02\n",
      "| epoch   6 |   106/  269 batches | lr 0.004429 |  3.70 ms | loss 0.06921 | ppl     1.07\n",
      "| epoch   6 |   159/  269 batches | lr 0.004429 |  3.65 ms | loss 0.02035 | ppl     1.02\n",
      "| epoch   6 |   212/  269 batches | lr 0.004429 |  3.64 ms | loss 0.03873 | ppl     1.04\n",
      "| epoch   6 |   265/  269 batches | lr 0.004429 |  3.64 ms | loss 0.06045 | ppl     1.06\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   6 | time:  1.54s | valid loss 0.23171 | valid ppl     1.26\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   7 |    53/  269 batches | lr 0.004341 |  3.76 ms | loss 0.01926 | ppl     1.02\n",
      "| epoch   7 |   106/  269 batches | lr 0.004341 |  3.71 ms | loss 0.06238 | ppl     1.06\n",
      "| epoch   7 |   159/  269 batches | lr 0.004341 |  3.63 ms | loss 0.03620 | ppl     1.04\n",
      "| epoch   7 |   212/  269 batches | lr 0.004341 |  3.67 ms | loss 0.03215 | ppl     1.03\n",
      "| epoch   7 |   265/  269 batches | lr 0.004341 |  3.67 ms | loss 0.04544 | ppl     1.05\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   7 | time:  1.55s | valid loss 0.25347 | valid ppl     1.29\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   8 |    53/  269 batches | lr 0.004254 |  3.73 ms | loss 0.01744 | ppl     1.02\n",
      "| epoch   8 |   106/  269 batches | lr 0.004254 |  3.60 ms | loss 0.06746 | ppl     1.07\n",
      "| epoch   8 |   159/  269 batches | lr 0.004254 |  3.63 ms | loss 0.03047 | ppl     1.03\n",
      "| epoch   8 |   212/  269 batches | lr 0.004254 |  3.62 ms | loss 0.02867 | ppl     1.03\n",
      "| epoch   8 |   265/  269 batches | lr 0.004254 |  3.92 ms | loss 0.03831 | ppl     1.04\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   8 | time:  1.55s | valid loss 0.33797 | valid ppl     1.40\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch   9 |    53/  269 batches | lr 0.004169 |  3.76 ms | loss 0.02175 | ppl     1.02\n",
      "| epoch   9 |   106/  269 batches | lr 0.004169 |  3.68 ms | loss 0.16891 | ppl     1.18\n",
      "| epoch   9 |   159/  269 batches | lr 0.004169 |  3.68 ms | loss 0.17944 | ppl     1.20\n",
      "| epoch   9 |   212/  269 batches | lr 0.004169 |  3.94 ms | loss 0.03528 | ppl     1.04\n",
      "| epoch   9 |   265/  269 batches | lr 0.004169 |  3.69 ms | loss 0.06165 | ppl     1.06\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch   9 | time:  1.56s | valid loss 0.46581 | valid ppl     1.59\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  10 |    53/  269 batches | lr 0.004085 |  3.77 ms | loss 0.03203 | ppl     1.03\n",
      "| epoch  10 |   106/  269 batches | lr 0.004085 |  3.66 ms | loss 0.10386 | ppl     1.11\n",
      "| epoch  10 |   159/  269 batches | lr 0.004085 |  3.61 ms | loss 0.07520 | ppl     1.08\n",
      "| epoch  10 |   212/  269 batches | lr 0.004085 |  3.62 ms | loss 0.03212 | ppl     1.03\n",
      "| epoch  10 |   265/  269 batches | lr 0.004085 |  4.70 ms | loss 0.05586 | ppl     1.06\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  10 | time:  6.64s | valid loss 0.24490 | valid ppl     1.28\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  11 |    53/  269 batches | lr 0.004004 |  3.70 ms | loss 0.02039 | ppl     1.02\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arty/anaconda3/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  11 |   106/  269 batches | lr 0.004004 |  3.64 ms | loss 0.06529 | ppl     1.07\n",
      "| epoch  11 |   159/  269 batches | lr 0.004004 |  3.90 ms | loss 0.02500 | ppl     1.03\n",
      "| epoch  11 |   212/  269 batches | lr 0.004004 |  3.87 ms | loss 0.03236 | ppl     1.03\n",
      "| epoch  11 |   265/  269 batches | lr 0.004004 |  3.85 ms | loss 0.05052 | ppl     1.05\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  11 | time:  1.57s | valid loss 0.29212 | valid ppl     1.34\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  12 |    53/  269 batches | lr 0.003924 |  4.13 ms | loss 0.02111 | ppl     1.02\n",
      "| epoch  12 |   106/  269 batches | lr 0.003924 |  4.54 ms | loss 0.08909 | ppl     1.09\n",
      "| epoch  12 |   159/  269 batches | lr 0.003924 |  4.97 ms | loss 0.07513 | ppl     1.08\n",
      "| epoch  12 |   212/  269 batches | lr 0.003924 |  5.09 ms | loss 0.03056 | ppl     1.03\n",
      "| epoch  12 |   265/  269 batches | lr 0.003924 |  4.57 ms | loss 0.05503 | ppl     1.06\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  12 | time:  1.81s | valid loss 0.27834 | valid ppl     1.32\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  13 |    53/  269 batches | lr 0.003845 |  3.80 ms | loss 0.02137 | ppl     1.02\n",
      "| epoch  13 |   106/  269 batches | lr 0.003845 |  3.72 ms | loss 0.09000 | ppl     1.09\n",
      "| epoch  13 |   159/  269 batches | lr 0.003845 |  3.81 ms | loss 0.08238 | ppl     1.09\n",
      "| epoch  13 |   212/  269 batches | lr 0.003845 |  4.14 ms | loss 0.03010 | ppl     1.03\n",
      "| epoch  13 |   265/  269 batches | lr 0.003845 |  3.64 ms | loss 0.05686 | ppl     1.06\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  13 | time:  1.58s | valid loss 0.26433 | valid ppl     1.30\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  14 |    53/  269 batches | lr 0.003768 |  3.77 ms | loss 0.02370 | ppl     1.02\n",
      "| epoch  14 |   106/  269 batches | lr 0.003768 |  3.63 ms | loss 0.11906 | ppl     1.13\n",
      "| epoch  14 |   159/  269 batches | lr 0.003768 |  3.62 ms | loss 0.19827 | ppl     1.22\n",
      "| epoch  14 |   212/  269 batches | lr 0.003768 |  3.62 ms | loss 0.02857 | ppl     1.03\n",
      "| epoch  14 |   265/  269 batches | lr 0.003768 |  3.65 ms | loss 0.05674 | ppl     1.06\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  14 | time:  1.54s | valid loss 0.27535 | valid ppl     1.32\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  15 |    53/  269 batches | lr 0.003693 |  3.76 ms | loss 0.02811 | ppl     1.03\n",
      "| epoch  15 |   106/  269 batches | lr 0.003693 |  4.23 ms | loss 0.12454 | ppl     1.13\n",
      "| epoch  15 |   159/  269 batches | lr 0.003693 |  4.47 ms | loss 0.19116 | ppl     1.21\n",
      "| epoch  15 |   212/  269 batches | lr 0.003693 |  5.02 ms | loss 0.03018 | ppl     1.03\n",
      "| epoch  15 |   265/  269 batches | lr 0.003693 |  4.01 ms | loss 0.05572 | ppl     1.06\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  15 | time:  1.71s | valid loss 0.28092 | valid ppl     1.32\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  16 |    53/  269 batches | lr 0.003619 |  4.02 ms | loss 0.02939 | ppl     1.03\n",
      "| epoch  16 |   106/  269 batches | lr 0.003619 |  3.63 ms | loss 0.13047 | ppl     1.14\n",
      "| epoch  16 |   159/  269 batches | lr 0.003619 |  3.66 ms | loss 0.17816 | ppl     1.20\n",
      "| epoch  16 |   212/  269 batches | lr 0.003619 |  3.85 ms | loss 0.02671 | ppl     1.03\n",
      "| epoch  16 |   265/  269 batches | lr 0.003619 |  3.94 ms | loss 0.05694 | ppl     1.06\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  16 | time:  1.58s | valid loss 0.27501 | valid ppl     1.32\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  17 |    53/  269 batches | lr 0.003547 |  3.77 ms | loss 0.03125 | ppl     1.03\n",
      "| epoch  17 |   106/  269 batches | lr 0.003547 |  4.13 ms | loss 0.12943 | ppl     1.14\n",
      "| epoch  17 |   159/  269 batches | lr 0.003547 |  3.68 ms | loss 0.18932 | ppl     1.21\n",
      "| epoch  17 |   212/  269 batches | lr 0.003547 |  3.63 ms | loss 0.02736 | ppl     1.03\n",
      "| epoch  17 |   265/  269 batches | lr 0.003547 |  3.68 ms | loss 0.05140 | ppl     1.05\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  17 | time:  1.57s | valid loss 0.24710 | valid ppl     1.28\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  18 |    53/  269 batches | lr 0.003476 |  3.80 ms | loss 0.02911 | ppl     1.03\n",
      "| epoch  18 |   106/  269 batches | lr 0.003476 |  3.67 ms | loss 0.13744 | ppl     1.15\n",
      "| epoch  18 |   159/  269 batches | lr 0.003476 |  3.67 ms | loss 0.16014 | ppl     1.17\n",
      "| epoch  18 |   212/  269 batches | lr 0.003476 |  3.66 ms | loss 0.03122 | ppl     1.03\n",
      "| epoch  18 |   265/  269 batches | lr 0.003476 |  3.66 ms | loss 0.05114 | ppl     1.05\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  18 | time:  1.54s | valid loss 0.21815 | valid ppl     1.24\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  19 |    53/  269 batches | lr 0.003406 |  3.77 ms | loss 0.02693 | ppl     1.03\n",
      "| epoch  19 |   106/  269 batches | lr 0.003406 |  3.65 ms | loss 0.12987 | ppl     1.14\n",
      "| epoch  19 |   159/  269 batches | lr 0.003406 |  3.69 ms | loss 0.12028 | ppl     1.13\n",
      "| epoch  19 |   212/  269 batches | lr 0.003406 |  3.67 ms | loss 0.03272 | ppl     1.03\n",
      "| epoch  19 |   265/  269 batches | lr 0.003406 |  3.65 ms | loss 0.05128 | ppl     1.05\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  19 | time:  1.54s | valid loss 0.23328 | valid ppl     1.26\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  20 |    53/  269 batches | lr 0.003338 |  3.79 ms | loss 0.02691 | ppl     1.03\n",
      "| epoch  20 |   106/  269 batches | lr 0.003338 |  3.67 ms | loss 0.13324 | ppl     1.14\n",
      "| epoch  20 |   159/  269 batches | lr 0.003338 |  3.66 ms | loss 0.14036 | ppl     1.15\n",
      "| epoch  20 |   212/  269 batches | lr 0.003338 |  3.65 ms | loss 0.03095 | ppl     1.03\n",
      "| epoch  20 |   265/  269 batches | lr 0.003338 |  3.68 ms | loss 0.05033 | ppl     1.05\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  20 | time:  6.38s | valid loss 0.21437 | valid ppl     1.24\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arty/anaconda3/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  21 |    53/  269 batches | lr 0.003271 |  3.83 ms | loss 0.02457 | ppl     1.02\n",
      "| epoch  21 |   106/  269 batches | lr 0.003271 |  3.76 ms | loss 0.14554 | ppl     1.16\n",
      "| epoch  21 |   159/  269 batches | lr 0.003271 |  4.75 ms | loss 0.19785 | ppl     1.22\n",
      "| epoch  21 |   212/  269 batches | lr 0.003271 |  3.68 ms | loss 0.03450 | ppl     1.04\n",
      "| epoch  21 |   265/  269 batches | lr 0.003271 |  3.71 ms | loss 0.04802 | ppl     1.05\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  21 | time:  1.62s | valid loss 0.22071 | valid ppl     1.25\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  22 |    53/  269 batches | lr 0.003206 |  3.84 ms | loss 0.02426 | ppl     1.02\n",
      "| epoch  22 |   106/  269 batches | lr 0.003206 |  3.95 ms | loss 0.14691 | ppl     1.16\n",
      "| epoch  22 |   159/  269 batches | lr 0.003206 |  5.20 ms | loss 0.22386 | ppl     1.25\n",
      "| epoch  22 |   212/  269 batches | lr 0.003206 |  5.30 ms | loss 0.03933 | ppl     1.04\n",
      "| epoch  22 |   265/  269 batches | lr 0.003206 |  3.73 ms | loss 0.04711 | ppl     1.05\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  22 | time:  1.74s | valid loss 0.22179 | valid ppl     1.25\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  23 |    53/  269 batches | lr 0.003142 |  3.80 ms | loss 0.02477 | ppl     1.03\n",
      "| epoch  23 |   106/  269 batches | lr 0.003142 |  3.70 ms | loss 0.13893 | ppl     1.15\n",
      "| epoch  23 |   159/  269 batches | lr 0.003142 |  3.85 ms | loss 0.18308 | ppl     1.20\n",
      "| epoch  23 |   212/  269 batches | lr 0.003142 |  3.69 ms | loss 0.02940 | ppl     1.03\n",
      "| epoch  23 |   265/  269 batches | lr 0.003142 |  3.72 ms | loss 0.05161 | ppl     1.05\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  23 | time:  1.56s | valid loss 0.21963 | valid ppl     1.25\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  24 |    53/  269 batches | lr 0.003079 |  3.84 ms | loss 0.02469 | ppl     1.02\n",
      "| epoch  24 |   106/  269 batches | lr 0.003079 |  3.77 ms | loss 0.14976 | ppl     1.16\n",
      "| epoch  24 |   159/  269 batches | lr 0.003079 |  3.73 ms | loss 0.20478 | ppl     1.23\n",
      "| epoch  24 |   212/  269 batches | lr 0.003079 |  3.68 ms | loss 0.02677 | ppl     1.03\n",
      "| epoch  24 |   265/  269 batches | lr 0.003079 |  3.78 ms | loss 0.05436 | ppl     1.06\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  24 | time:  1.56s | valid loss 0.23031 | valid ppl     1.26\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  25 |    53/  269 batches | lr 0.003017 |  3.83 ms | loss 0.02747 | ppl     1.03\n",
      "| epoch  25 |   106/  269 batches | lr 0.003017 |  3.80 ms | loss 0.15200 | ppl     1.16\n",
      "| epoch  25 |   159/  269 batches | lr 0.003017 |  3.83 ms | loss 0.21973 | ppl     1.25\n",
      "| epoch  25 |   212/  269 batches | lr 0.003017 |  4.01 ms | loss 0.03327 | ppl     1.03\n",
      "| epoch  25 |   265/  269 batches | lr 0.003017 |  4.03 ms | loss 0.05116 | ppl     1.05\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  25 | time:  1.61s | valid loss 0.23384 | valid ppl     1.26\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  26 |    53/  269 batches | lr 0.002957 |  3.83 ms | loss 0.02634 | ppl     1.03\n",
      "| epoch  26 |   106/  269 batches | lr 0.002957 |  3.72 ms | loss 0.15338 | ppl     1.17\n",
      "| epoch  26 |   159/  269 batches | lr 0.002957 |  3.69 ms | loss 0.20088 | ppl     1.22\n",
      "| epoch  26 |   212/  269 batches | lr 0.002957 |  3.95 ms | loss 0.02745 | ppl     1.03\n",
      "| epoch  26 |   265/  269 batches | lr 0.002957 |  3.70 ms | loss 0.05430 | ppl     1.06\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  26 | time:  1.57s | valid loss 0.23124 | valid ppl     1.26\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  27 |    53/  269 batches | lr 0.002898 |  3.82 ms | loss 0.03013 | ppl     1.03\n",
      "| epoch  27 |   106/  269 batches | lr 0.002898 |  4.06 ms | loss 0.16050 | ppl     1.17\n",
      "| epoch  27 |   159/  269 batches | lr 0.002898 |  4.94 ms | loss 0.21674 | ppl     1.24\n",
      "| epoch  27 |   212/  269 batches | lr 0.002898 |  5.14 ms | loss 0.02930 | ppl     1.03\n",
      "| epoch  27 |   265/  269 batches | lr 0.002898 |  4.22 ms | loss 0.05298 | ppl     1.05\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  27 | time:  1.75s | valid loss 0.22865 | valid ppl     1.26\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  28 |    53/  269 batches | lr 0.002840 |  4.02 ms | loss 0.02752 | ppl     1.03\n",
      "| epoch  28 |   106/  269 batches | lr 0.002840 |  4.25 ms | loss 0.15967 | ppl     1.17\n",
      "| epoch  28 |   159/  269 batches | lr 0.002840 |  3.87 ms | loss 0.21114 | ppl     1.24\n",
      "| epoch  28 |   212/  269 batches | lr 0.002840 |  3.86 ms | loss 0.03225 | ppl     1.03\n",
      "| epoch  28 |   265/  269 batches | lr 0.002840 |  4.02 ms | loss 0.05265 | ppl     1.05\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  28 | time:  1.64s | valid loss 0.21989 | valid ppl     1.25\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  29 |    53/  269 batches | lr 0.002783 |  4.43 ms | loss 0.02768 | ppl     1.03\n",
      "| epoch  29 |   106/  269 batches | lr 0.002783 |  4.71 ms | loss 0.16511 | ppl     1.18\n",
      "| epoch  29 |   159/  269 batches | lr 0.002783 |  3.65 ms | loss 0.21200 | ppl     1.24\n",
      "| epoch  29 |   212/  269 batches | lr 0.002783 |  3.64 ms | loss 0.03291 | ppl     1.03\n",
      "| epoch  29 |   265/  269 batches | lr 0.002783 |  3.98 ms | loss 0.05037 | ppl     1.05\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  29 | time:  1.65s | valid loss 0.22573 | valid ppl     1.25\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  30 |    53/  269 batches | lr 0.002727 |  3.79 ms | loss 0.02819 | ppl     1.03\n",
      "| epoch  30 |   106/  269 batches | lr 0.002727 |  3.97 ms | loss 0.16433 | ppl     1.18\n",
      "| epoch  30 |   159/  269 batches | lr 0.002727 |  3.72 ms | loss 0.21330 | ppl     1.24\n",
      "| epoch  30 |   212/  269 batches | lr 0.002727 |  3.72 ms | loss 0.04196 | ppl     1.04\n",
      "| epoch  30 |   265/  269 batches | lr 0.002727 |  3.69 ms | loss 0.04852 | ppl     1.05\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  30 | time:  6.46s | valid loss 0.22803 | valid ppl     1.26\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  31 |    53/  269 batches | lr 0.002673 |  3.68 ms | loss 0.02802 | ppl     1.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arty/anaconda3/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  31 |   106/  269 batches | lr 0.002673 |  3.64 ms | loss 0.17321 | ppl     1.19\n",
      "| epoch  31 |   159/  269 batches | lr 0.002673 |  3.68 ms | loss 0.21519 | ppl     1.24\n",
      "| epoch  31 |   212/  269 batches | lr 0.002673 |  4.61 ms | loss 0.08258 | ppl     1.09\n",
      "| epoch  31 |   265/  269 batches | lr 0.002673 |  6.52 ms | loss 0.04601 | ppl     1.05\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  31 | time:  1.74s | valid loss 0.23666 | valid ppl     1.27\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  32 |    53/  269 batches | lr 0.002619 |  3.79 ms | loss 0.02986 | ppl     1.03\n",
      "| epoch  32 |   106/  269 batches | lr 0.002619 |  3.66 ms | loss 0.17374 | ppl     1.19\n",
      "| epoch  32 |   159/  269 batches | lr 0.002619 |  3.69 ms | loss 0.22234 | ppl     1.25\n",
      "| epoch  32 |   212/  269 batches | lr 0.002619 |  3.67 ms | loss 0.08747 | ppl     1.09\n",
      "| epoch  32 |   265/  269 batches | lr 0.002619 |  3.64 ms | loss 0.04636 | ppl     1.05\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  32 | time:  1.55s | valid loss 0.23132 | valid ppl     1.26\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  33 |    53/  269 batches | lr 0.002567 |  3.82 ms | loss 0.02974 | ppl     1.03\n",
      "| epoch  33 |   106/  269 batches | lr 0.002567 |  3.68 ms | loss 0.16660 | ppl     1.18\n",
      "| epoch  33 |   159/  269 batches | lr 0.002567 |  3.72 ms | loss 0.21645 | ppl     1.24\n",
      "| epoch  33 |   212/  269 batches | lr 0.002567 |  3.63 ms | loss 0.09666 | ppl     1.10\n",
      "| epoch  33 |   265/  269 batches | lr 0.002567 |  3.65 ms | loss 0.04336 | ppl     1.04\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  33 | time:  1.54s | valid loss 0.23878 | valid ppl     1.27\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  34 |    53/  269 batches | lr 0.002516 |  3.80 ms | loss 0.03146 | ppl     1.03\n",
      "| epoch  34 |   106/  269 batches | lr 0.002516 |  5.77 ms | loss 0.16432 | ppl     1.18\n",
      "| epoch  34 |   159/  269 batches | lr 0.002516 |  3.67 ms | loss 0.21626 | ppl     1.24\n",
      "| epoch  34 |   212/  269 batches | lr 0.002516 |  3.92 ms | loss 0.08543 | ppl     1.09\n",
      "| epoch  34 |   265/  269 batches | lr 0.002516 |  3.74 ms | loss 0.04446 | ppl     1.05\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  34 | time:  1.68s | valid loss 0.23733 | valid ppl     1.27\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  35 |    53/  269 batches | lr 0.002465 |  4.34 ms | loss 0.03047 | ppl     1.03\n",
      "| epoch  35 |   106/  269 batches | lr 0.002465 |  3.86 ms | loss 0.16665 | ppl     1.18\n",
      "| epoch  35 |   159/  269 batches | lr 0.002465 |  4.25 ms | loss 0.21519 | ppl     1.24\n",
      "| epoch  35 |   212/  269 batches | lr 0.002465 |  4.46 ms | loss 0.07953 | ppl     1.08\n",
      "| epoch  35 |   265/  269 batches | lr 0.002465 |  4.00 ms | loss 0.04376 | ppl     1.04\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  35 | time:  1.68s | valid loss 0.24423 | valid ppl     1.28\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  36 |    53/  269 batches | lr 0.002416 |  4.29 ms | loss 0.03190 | ppl     1.03\n",
      "| epoch  36 |   106/  269 batches | lr 0.002416 |  4.51 ms | loss 0.16502 | ppl     1.18\n",
      "| epoch  36 |   159/  269 batches | lr 0.002416 |  3.77 ms | loss 0.21501 | ppl     1.24\n",
      "| epoch  36 |   212/  269 batches | lr 0.002416 |  3.74 ms | loss 0.09086 | ppl     1.10\n",
      "| epoch  36 |   265/  269 batches | lr 0.002416 |  3.66 ms | loss 0.04383 | ppl     1.04\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  36 | time:  1.64s | valid loss 0.24444 | valid ppl     1.28\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  37 |    53/  269 batches | lr 0.002368 |  5.08 ms | loss 0.03224 | ppl     1.03\n",
      "| epoch  37 |   106/  269 batches | lr 0.002368 |  5.03 ms | loss 0.16516 | ppl     1.18\n",
      "| epoch  37 |   159/  269 batches | lr 0.002368 |  4.97 ms | loss 0.21382 | ppl     1.24\n",
      "| epoch  37 |   212/  269 batches | lr 0.002368 |  3.81 ms | loss 0.08619 | ppl     1.09\n",
      "| epoch  37 |   265/  269 batches | lr 0.002368 |  3.64 ms | loss 0.04306 | ppl     1.04\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  37 | time:  1.77s | valid loss 0.24388 | valid ppl     1.28\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  38 |    53/  269 batches | lr 0.002320 |  3.86 ms | loss 0.03278 | ppl     1.03\n",
      "| epoch  38 |   106/  269 batches | lr 0.002320 |  3.86 ms | loss 0.16498 | ppl     1.18\n",
      "| epoch  38 |   159/  269 batches | lr 0.002320 |  3.79 ms | loss 0.21528 | ppl     1.24\n",
      "| epoch  38 |   212/  269 batches | lr 0.002320 |  3.65 ms | loss 0.08539 | ppl     1.09\n",
      "| epoch  38 |   265/  269 batches | lr 0.002320 |  3.76 ms | loss 0.04353 | ppl     1.04\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  38 | time:  1.58s | valid loss 0.24229 | valid ppl     1.27\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  39 |    53/  269 batches | lr 0.002274 |  3.84 ms | loss 0.03160 | ppl     1.03\n",
      "| epoch  39 |   106/  269 batches | lr 0.002274 |  3.83 ms | loss 0.16122 | ppl     1.17\n",
      "| epoch  39 |   159/  269 batches | lr 0.002274 |  5.07 ms | loss 0.21533 | ppl     1.24\n",
      "| epoch  39 |   212/  269 batches | lr 0.002274 |  3.99 ms | loss 0.07420 | ppl     1.08\n",
      "| epoch  39 |   265/  269 batches | lr 0.002274 |  4.29 ms | loss 0.04349 | ppl     1.04\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  39 | time:  1.71s | valid loss 0.24806 | valid ppl     1.28\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  40 |    53/  269 batches | lr 0.002229 |  6.07 ms | loss 0.03294 | ppl     1.03\n",
      "| epoch  40 |   106/  269 batches | lr 0.002229 |  4.00 ms | loss 0.16465 | ppl     1.18\n",
      "| epoch  40 |   159/  269 batches | lr 0.002229 |  3.77 ms | loss 0.21476 | ppl     1.24\n",
      "| epoch  40 |   212/  269 batches | lr 0.002229 |  3.67 ms | loss 0.07712 | ppl     1.08\n",
      "| epoch  40 |   265/  269 batches | lr 0.002229 |  3.71 ms | loss 0.04328 | ppl     1.04\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  40 | time:  6.58s | valid loss 0.24943 | valid ppl     1.28\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  41 |    53/  269 batches | lr 0.002184 |  3.73 ms | loss 0.03398 | ppl     1.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arty/anaconda3/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  41 |   106/  269 batches | lr 0.002184 |  3.69 ms | loss 0.16255 | ppl     1.18\n",
      "| epoch  41 |   159/  269 batches | lr 0.002184 |  3.80 ms | loss 0.22172 | ppl     1.25\n",
      "| epoch  41 |   212/  269 batches | lr 0.002184 |  3.69 ms | loss 0.07035 | ppl     1.07\n",
      "| epoch  41 |   265/  269 batches | lr 0.002184 |  3.72 ms | loss 0.04290 | ppl     1.04\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  41 | time:  1.56s | valid loss 0.24764 | valid ppl     1.28\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  42 |    53/  269 batches | lr 0.002140 |  3.86 ms | loss 0.03322 | ppl     1.03\n",
      "| epoch  42 |   106/  269 batches | lr 0.002140 |  3.64 ms | loss 0.16061 | ppl     1.17\n",
      "| epoch  42 |   159/  269 batches | lr 0.002140 |  3.96 ms | loss 0.22887 | ppl     1.26\n",
      "| epoch  42 |   212/  269 batches | lr 0.002140 |  3.65 ms | loss 0.06726 | ppl     1.07\n",
      "| epoch  42 |   265/  269 batches | lr 0.002140 |  3.71 ms | loss 0.04332 | ppl     1.04\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  42 | time:  1.57s | valid loss 0.25209 | valid ppl     1.29\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  43 |    53/  269 batches | lr 0.002097 |  3.83 ms | loss 0.03400 | ppl     1.03\n",
      "| epoch  43 |   106/  269 batches | lr 0.002097 |  3.82 ms | loss 0.16004 | ppl     1.17\n",
      "| epoch  43 |   159/  269 batches | lr 0.002097 |  3.79 ms | loss 0.22786 | ppl     1.26\n",
      "| epoch  43 |   212/  269 batches | lr 0.002097 |  3.74 ms | loss 0.06565 | ppl     1.07\n",
      "| epoch  43 |   265/  269 batches | lr 0.002097 |  3.71 ms | loss 0.04355 | ppl     1.04\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  43 | time:  1.57s | valid loss 0.25317 | valid ppl     1.29\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  44 |    53/  269 batches | lr 0.002055 |  3.83 ms | loss 0.03454 | ppl     1.04\n",
      "| epoch  44 |   106/  269 batches | lr 0.002055 |  3.87 ms | loss 0.15925 | ppl     1.17\n",
      "| epoch  44 |   159/  269 batches | lr 0.002055 |  3.65 ms | loss 0.21503 | ppl     1.24\n",
      "| epoch  44 |   212/  269 batches | lr 0.002055 |  3.67 ms | loss 0.07157 | ppl     1.07\n",
      "| epoch  44 |   265/  269 batches | lr 0.002055 |  3.68 ms | loss 0.04358 | ppl     1.04\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  44 | time:  1.56s | valid loss 0.25074 | valid ppl     1.28\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  45 |    53/  269 batches | lr 0.002014 |  3.77 ms | loss 0.03477 | ppl     1.04\n",
      "| epoch  45 |   106/  269 batches | lr 0.002014 |  3.67 ms | loss 0.16023 | ppl     1.17\n",
      "| epoch  45 |   159/  269 batches | lr 0.002014 |  3.83 ms | loss 0.22007 | ppl     1.25\n",
      "| epoch  45 |   212/  269 batches | lr 0.002014 |  3.65 ms | loss 0.08033 | ppl     1.08\n",
      "| epoch  45 |   265/  269 batches | lr 0.002014 |  3.67 ms | loss 0.04192 | ppl     1.04\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  45 | time:  1.56s | valid loss 0.24635 | valid ppl     1.28\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  46 |    53/  269 batches | lr 0.001974 |  3.86 ms | loss 0.03394 | ppl     1.03\n",
      "| epoch  46 |   106/  269 batches | lr 0.001974 |  3.78 ms | loss 0.16034 | ppl     1.17\n",
      "| epoch  46 |   159/  269 batches | lr 0.001974 |  3.67 ms | loss 0.23387 | ppl     1.26\n",
      "| epoch  46 |   212/  269 batches | lr 0.001974 |  4.11 ms | loss 0.07760 | ppl     1.08\n",
      "| epoch  46 |   265/  269 batches | lr 0.001974 |  3.77 ms | loss 0.04254 | ppl     1.04\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  46 | time:  1.59s | valid loss 0.24697 | valid ppl     1.28\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  47 |    53/  269 batches | lr 0.001935 |  3.82 ms | loss 0.03314 | ppl     1.03\n",
      "| epoch  47 |   106/  269 batches | lr 0.001935 |  3.73 ms | loss 0.15968 | ppl     1.17\n",
      "| epoch  47 |   159/  269 batches | lr 0.001935 |  3.78 ms | loss 0.22809 | ppl     1.26\n",
      "| epoch  47 |   212/  269 batches | lr 0.001935 |  3.76 ms | loss 0.06825 | ppl     1.07\n",
      "| epoch  47 |   265/  269 batches | lr 0.001935 |  3.89 ms | loss 0.04275 | ppl     1.04\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  47 | time:  1.58s | valid loss 0.25220 | valid ppl     1.29\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  48 |    53/  269 batches | lr 0.001896 |  4.00 ms | loss 0.03492 | ppl     1.04\n",
      "| epoch  48 |   106/  269 batches | lr 0.001896 |  4.79 ms | loss 0.15726 | ppl     1.17\n",
      "| epoch  48 |   159/  269 batches | lr 0.001896 |  5.11 ms | loss 0.21760 | ppl     1.24\n",
      "| epoch  48 |   212/  269 batches | lr 0.001896 |  5.10 ms | loss 0.07854 | ppl     1.08\n",
      "| epoch  48 |   265/  269 batches | lr 0.001896 |  3.90 ms | loss 0.04238 | ppl     1.04\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  48 | time:  1.79s | valid loss 0.24699 | valid ppl     1.28\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  49 |    53/  269 batches | lr 0.001858 |  3.87 ms | loss 0.03417 | ppl     1.03\n",
      "| epoch  49 |   106/  269 batches | lr 0.001858 |  3.77 ms | loss 0.15795 | ppl     1.17\n",
      "| epoch  49 |   159/  269 batches | lr 0.001858 |  3.90 ms | loss 0.23668 | ppl     1.27\n",
      "| epoch  49 |   212/  269 batches | lr 0.001858 |  3.85 ms | loss 0.09312 | ppl     1.10\n",
      "| epoch  49 |   265/  269 batches | lr 0.001858 |  3.82 ms | loss 0.04087 | ppl     1.04\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  49 | time:  1.59s | valid loss 0.24338 | valid ppl     1.28\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  50 |    53/  269 batches | lr 0.001821 |  3.88 ms | loss 0.03311 | ppl     1.03\n",
      "| epoch  50 |   106/  269 batches | lr 0.001821 |  3.91 ms | loss 0.15856 | ppl     1.17\n",
      "| epoch  50 |   159/  269 batches | lr 0.001821 |  3.82 ms | loss 0.23745 | ppl     1.27\n",
      "| epoch  50 |   212/  269 batches | lr 0.001821 |  3.77 ms | loss 0.08797 | ppl     1.09\n",
      "| epoch  50 |   265/  269 batches | lr 0.001821 |  3.74 ms | loss 0.04204 | ppl     1.04\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  50 | time:  6.29s | valid loss 0.24549 | valid ppl     1.28\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  51 |    53/  269 batches | lr 0.001784 |  3.76 ms | loss 0.03418 | ppl     1.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arty/anaconda3/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  51 |   106/  269 batches | lr 0.001784 |  3.65 ms | loss 0.15912 | ppl     1.17\n",
      "| epoch  51 |   159/  269 batches | lr 0.001784 |  3.68 ms | loss 0.24115 | ppl     1.27\n",
      "| epoch  51 |   212/  269 batches | lr 0.001784 |  3.77 ms | loss 0.08073 | ppl     1.08\n",
      "| epoch  51 |   265/  269 batches | lr 0.001784 |  4.02 ms | loss 0.04098 | ppl     1.04\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  51 | time:  1.57s | valid loss 0.24114 | valid ppl     1.27\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  52 |    53/  269 batches | lr 0.001749 |  3.91 ms | loss 0.03330 | ppl     1.03\n",
      "| epoch  52 |   106/  269 batches | lr 0.001749 |  4.56 ms | loss 0.15771 | ppl     1.17\n",
      "| epoch  52 |   159/  269 batches | lr 0.001749 |  4.78 ms | loss 0.24240 | ppl     1.27\n",
      "| epoch  52 |   212/  269 batches | lr 0.001749 |  4.89 ms | loss 0.06917 | ppl     1.07\n",
      "| epoch  52 |   265/  269 batches | lr 0.001749 |  4.61 ms | loss 0.04011 | ppl     1.04\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  52 | time:  1.78s | valid loss 0.23254 | valid ppl     1.26\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  53 |    53/  269 batches | lr 0.001714 |  3.89 ms | loss 0.03027 | ppl     1.03\n",
      "| epoch  53 |   106/  269 batches | lr 0.001714 |  3.67 ms | loss 0.15332 | ppl     1.17\n",
      "| epoch  53 |   159/  269 batches | lr 0.001714 |  4.41 ms | loss 0.23860 | ppl     1.27\n",
      "| epoch  53 |   212/  269 batches | lr 0.001714 |  5.47 ms | loss 0.07447 | ppl     1.08\n",
      "| epoch  53 |   265/  269 batches | lr 0.001714 |  5.35 ms | loss 0.03911 | ppl     1.04\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  53 | time:  1.78s | valid loss 0.23421 | valid ppl     1.26\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  54 |    53/  269 batches | lr 0.001679 |  3.92 ms | loss 0.03055 | ppl     1.03\n",
      "| epoch  54 |   106/  269 batches | lr 0.001679 |  3.71 ms | loss 0.15826 | ppl     1.17\n",
      "| epoch  54 |   159/  269 batches | lr 0.001679 |  3.75 ms | loss 0.24055 | ppl     1.27\n",
      "| epoch  54 |   212/  269 batches | lr 0.001679 |  3.70 ms | loss 0.08318 | ppl     1.09\n",
      "| epoch  54 |   265/  269 batches | lr 0.001679 |  4.16 ms | loss 0.04039 | ppl     1.04\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  54 | time:  1.59s | valid loss 0.24120 | valid ppl     1.27\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  55 |    53/  269 batches | lr 0.001646 |  3.92 ms | loss 0.03273 | ppl     1.03\n",
      "| epoch  55 |   106/  269 batches | lr 0.001646 |  4.11 ms | loss 0.15807 | ppl     1.17\n",
      "| epoch  55 |   159/  269 batches | lr 0.001646 |  3.86 ms | loss 0.23974 | ppl     1.27\n",
      "| epoch  55 |   212/  269 batches | lr 0.001646 |  5.47 ms | loss 0.08296 | ppl     1.09\n",
      "| epoch  55 |   265/  269 batches | lr 0.001646 |  5.17 ms | loss 0.04189 | ppl     1.04\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  55 | time:  1.77s | valid loss 0.24057 | valid ppl     1.27\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  56 |    53/  269 batches | lr 0.001613 |  4.25 ms | loss 0.03253 | ppl     1.03\n",
      "| epoch  56 |   106/  269 batches | lr 0.001613 |  3.78 ms | loss 0.15708 | ppl     1.17\n",
      "| epoch  56 |   159/  269 batches | lr 0.001613 |  3.64 ms | loss 0.23571 | ppl     1.27\n",
      "| epoch  56 |   212/  269 batches | lr 0.001613 |  3.71 ms | loss 0.08967 | ppl     1.09\n",
      "| epoch  56 |   265/  269 batches | lr 0.001613 |  3.79 ms | loss 0.04731 | ppl     1.05\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  56 | time:  1.59s | valid loss 0.22701 | valid ppl     1.25\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  57 |    53/  269 batches | lr 0.001581 |  3.86 ms | loss 0.03043 | ppl     1.03\n",
      "| epoch  57 |   106/  269 batches | lr 0.001581 |  3.91 ms | loss 0.16149 | ppl     1.18\n",
      "| epoch  57 |   159/  269 batches | lr 0.001581 |  3.83 ms | loss 0.21369 | ppl     1.24\n",
      "| epoch  57 |   212/  269 batches | lr 0.001581 |  3.74 ms | loss 0.08741 | ppl     1.09\n",
      "| epoch  57 |   265/  269 batches | lr 0.001581 |  3.75 ms | loss 0.04194 | ppl     1.04\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  57 | time:  1.58s | valid loss 0.23979 | valid ppl     1.27\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  58 |    53/  269 batches | lr 0.001549 |  3.87 ms | loss 0.03228 | ppl     1.03\n",
      "| epoch  58 |   106/  269 batches | lr 0.001549 |  3.83 ms | loss 0.15467 | ppl     1.17\n",
      "| epoch  58 |   159/  269 batches | lr 0.001549 |  3.90 ms | loss 0.22207 | ppl     1.25\n",
      "| epoch  58 |   212/  269 batches | lr 0.001549 |  3.77 ms | loss 0.07932 | ppl     1.08\n",
      "| epoch  58 |   265/  269 batches | lr 0.001549 |  4.62 ms | loss 0.04066 | ppl     1.04\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  58 | time:  1.65s | valid loss 0.24080 | valid ppl     1.27\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  59 |    53/  269 batches | lr 0.001518 |  3.86 ms | loss 0.03297 | ppl     1.03\n",
      "| epoch  59 |   106/  269 batches | lr 0.001518 |  3.90 ms | loss 0.15781 | ppl     1.17\n",
      "| epoch  59 |   159/  269 batches | lr 0.001518 |  3.73 ms | loss 0.22761 | ppl     1.26\n",
      "| epoch  59 |   212/  269 batches | lr 0.001518 |  3.89 ms | loss 0.08652 | ppl     1.09\n",
      "| epoch  59 |   265/  269 batches | lr 0.001518 |  3.82 ms | loss 0.04011 | ppl     1.04\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  59 | time:  1.60s | valid loss 0.23738 | valid ppl     1.27\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  60 |    53/  269 batches | lr 0.001488 |  3.82 ms | loss 0.03157 | ppl     1.03\n",
      "| epoch  60 |   106/  269 batches | lr 0.001488 |  3.68 ms | loss 0.15282 | ppl     1.17\n",
      "| epoch  60 |   159/  269 batches | lr 0.001488 |  5.22 ms | loss 0.23766 | ppl     1.27\n",
      "| epoch  60 |   212/  269 batches | lr 0.001488 |  5.04 ms | loss 0.08103 | ppl     1.08\n",
      "| epoch  60 |   265/  269 batches | lr 0.001488 |  5.19 ms | loss 0.03939 | ppl     1.04\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  60 | time:  6.67s | valid loss 0.23178 | valid ppl     1.26\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  61 |    53/  269 batches | lr 0.001458 |  3.74 ms | loss 0.02992 | ppl     1.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arty/anaconda3/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  61 |   106/  269 batches | lr 0.001458 |  3.74 ms | loss 0.15402 | ppl     1.17\n",
      "| epoch  61 |   159/  269 batches | lr 0.001458 |  3.87 ms | loss 0.24529 | ppl     1.28\n",
      "| epoch  61 |   212/  269 batches | lr 0.001458 |  3.74 ms | loss 0.06625 | ppl     1.07\n",
      "| epoch  61 |   265/  269 batches | lr 0.001458 |  3.79 ms | loss 0.03883 | ppl     1.04\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  61 | time:  1.57s | valid loss 0.23020 | valid ppl     1.26\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  62 |    53/  269 batches | lr 0.001429 |  3.83 ms | loss 0.02888 | ppl     1.03\n",
      "| epoch  62 |   106/  269 batches | lr 0.001429 |  3.76 ms | loss 0.15050 | ppl     1.16\n",
      "| epoch  62 |   159/  269 batches | lr 0.001429 |  3.81 ms | loss 0.24453 | ppl     1.28\n",
      "| epoch  62 |   212/  269 batches | lr 0.001429 |  5.36 ms | loss 0.06930 | ppl     1.07\n",
      "| epoch  62 |   265/  269 batches | lr 0.001429 |  6.12 ms | loss 0.03756 | ppl     1.04\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  62 | time:  1.78s | valid loss 0.23113 | valid ppl     1.26\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  63 |    53/  269 batches | lr 0.001400 |  3.88 ms | loss 0.02940 | ppl     1.03\n",
      "| epoch  63 |   106/  269 batches | lr 0.001400 |  3.68 ms | loss 0.14949 | ppl     1.16\n",
      "| epoch  63 |   159/  269 batches | lr 0.001400 |  3.72 ms | loss 0.24175 | ppl     1.27\n",
      "| epoch  63 |   212/  269 batches | lr 0.001400 |  3.70 ms | loss 0.06814 | ppl     1.07\n",
      "| epoch  63 |   265/  269 batches | lr 0.001400 |  3.75 ms | loss 0.03793 | ppl     1.04\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  63 | time:  1.57s | valid loss 0.23205 | valid ppl     1.26\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  64 |    53/  269 batches | lr 0.001372 |  3.87 ms | loss 0.02945 | ppl     1.03\n",
      "| epoch  64 |   106/  269 batches | lr 0.001372 |  3.71 ms | loss 0.14910 | ppl     1.16\n",
      "| epoch  64 |   159/  269 batches | lr 0.001372 |  3.73 ms | loss 0.23833 | ppl     1.27\n",
      "| epoch  64 |   212/  269 batches | lr 0.001372 |  3.70 ms | loss 0.06526 | ppl     1.07\n",
      "| epoch  64 |   265/  269 batches | lr 0.001372 |  3.73 ms | loss 0.03920 | ppl     1.04\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  64 | time:  1.56s | valid loss 0.23469 | valid ppl     1.26\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  65 |    53/  269 batches | lr 0.001345 |  3.78 ms | loss 0.03113 | ppl     1.03\n",
      "| epoch  65 |   106/  269 batches | lr 0.001345 |  3.67 ms | loss 0.15394 | ppl     1.17\n",
      "| epoch  65 |   159/  269 batches | lr 0.001345 |  3.63 ms | loss 0.22670 | ppl     1.25\n",
      "| epoch  65 |   212/  269 batches | lr 0.001345 |  3.65 ms | loss 0.08928 | ppl     1.09\n",
      "| epoch  65 |   265/  269 batches | lr 0.001345 |  3.70 ms | loss 0.04014 | ppl     1.04\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  65 | time:  1.55s | valid loss 0.23736 | valid ppl     1.27\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  66 |    53/  269 batches | lr 0.001318 |  3.81 ms | loss 0.03182 | ppl     1.03\n",
      "| epoch  66 |   106/  269 batches | lr 0.001318 |  3.65 ms | loss 0.15437 | ppl     1.17\n",
      "| epoch  66 |   159/  269 batches | lr 0.001318 |  3.68 ms | loss 0.23543 | ppl     1.27\n",
      "| epoch  66 |   212/  269 batches | lr 0.001318 |  3.65 ms | loss 0.08217 | ppl     1.09\n",
      "| epoch  66 |   265/  269 batches | lr 0.001318 |  3.91 ms | loss 0.03938 | ppl     1.04\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  66 | time:  1.56s | valid loss 0.23019 | valid ppl     1.26\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  67 |    53/  269 batches | lr 0.001292 |  3.88 ms | loss 0.02927 | ppl     1.03\n",
      "| epoch  67 |   106/  269 batches | lr 0.001292 |  3.64 ms | loss 0.15150 | ppl     1.16\n",
      "| epoch  67 |   159/  269 batches | lr 0.001292 |  3.66 ms | loss 0.24382 | ppl     1.28\n",
      "| epoch  67 |   212/  269 batches | lr 0.001292 |  3.69 ms | loss 0.06894 | ppl     1.07\n",
      "| epoch  67 |   265/  269 batches | lr 0.001292 |  3.70 ms | loss 0.03734 | ppl     1.04\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  67 | time:  1.56s | valid loss 0.23108 | valid ppl     1.26\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  68 |    53/  269 batches | lr 0.001266 |  3.86 ms | loss 0.02921 | ppl     1.03\n",
      "| epoch  68 |   106/  269 batches | lr 0.001266 |  3.72 ms | loss 0.14850 | ppl     1.16\n",
      "| epoch  68 |   159/  269 batches | lr 0.001266 |  3.73 ms | loss 0.24217 | ppl     1.27\n",
      "| epoch  68 |   212/  269 batches | lr 0.001266 |  5.61 ms | loss 0.07043 | ppl     1.07\n",
      "| epoch  68 |   265/  269 batches | lr 0.001266 |  4.16 ms | loss 0.03767 | ppl     1.04\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  68 | time:  1.70s | valid loss 0.23131 | valid ppl     1.26\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  69 |    53/  269 batches | lr 0.001240 |  3.87 ms | loss 0.02971 | ppl     1.03\n",
      "| epoch  69 |   106/  269 batches | lr 0.001240 |  3.83 ms | loss 0.14987 | ppl     1.16\n",
      "| epoch  69 |   159/  269 batches | lr 0.001240 |  4.44 ms | loss 0.24191 | ppl     1.27\n",
      "| epoch  69 |   212/  269 batches | lr 0.001240 |  4.35 ms | loss 0.06963 | ppl     1.07\n",
      "| epoch  69 |   265/  269 batches | lr 0.001240 |  4.38 ms | loss 0.03805 | ppl     1.04\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  69 | time:  1.68s | valid loss 0.23311 | valid ppl     1.26\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  70 |    53/  269 batches | lr 0.001216 |  3.99 ms | loss 0.03025 | ppl     1.03\n",
      "| epoch  70 |   106/  269 batches | lr 0.001216 |  3.85 ms | loss 0.14918 | ppl     1.16\n",
      "| epoch  70 |   159/  269 batches | lr 0.001216 |  4.75 ms | loss 0.23902 | ppl     1.27\n",
      "| epoch  70 |   212/  269 batches | lr 0.001216 |  3.86 ms | loss 0.06647 | ppl     1.07\n",
      "| epoch  70 |   265/  269 batches | lr 0.001216 |  3.76 ms | loss 0.03934 | ppl     1.04\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  70 | time:  6.71s | valid loss 0.23398 | valid ppl     1.26\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  71 |    53/  269 batches | lr 0.001191 |  3.75 ms | loss 0.03046 | ppl     1.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arty/anaconda3/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  71 |   106/  269 batches | lr 0.001191 |  3.80 ms | loss 0.15048 | ppl     1.16\n",
      "| epoch  71 |   159/  269 batches | lr 0.001191 |  5.61 ms | loss 0.24290 | ppl     1.27\n",
      "| epoch  71 |   212/  269 batches | lr 0.001191 |  3.93 ms | loss 0.06696 | ppl     1.07\n",
      "| epoch  71 |   265/  269 batches | lr 0.001191 |  3.73 ms | loss 0.03818 | ppl     1.04\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  71 | time:  1.68s | valid loss 0.23073 | valid ppl     1.26\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  72 |    53/  269 batches | lr 0.001167 |  3.83 ms | loss 0.02886 | ppl     1.03\n",
      "| epoch  72 |   106/  269 batches | lr 0.001167 |  4.24 ms | loss 0.14909 | ppl     1.16\n",
      "| epoch  72 |   159/  269 batches | lr 0.001167 |  4.98 ms | loss 0.23895 | ppl     1.27\n",
      "| epoch  72 |   212/  269 batches | lr 0.001167 |  4.48 ms | loss 0.06378 | ppl     1.07\n",
      "| epoch  72 |   265/  269 batches | lr 0.001167 |  3.80 ms | loss 0.03896 | ppl     1.04\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  72 | time:  1.72s | valid loss 0.22944 | valid ppl     1.26\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  73 |    53/  269 batches | lr 0.001144 |  3.97 ms | loss 0.02872 | ppl     1.03\n",
      "| epoch  73 |   106/  269 batches | lr 0.001144 |  5.19 ms | loss 0.15009 | ppl     1.16\n",
      "| epoch  73 |   159/  269 batches | lr 0.001144 |  3.85 ms | loss 0.24408 | ppl     1.28\n",
      "| epoch  73 |   212/  269 batches | lr 0.001144 |  3.67 ms | loss 0.06627 | ppl     1.07\n",
      "| epoch  73 |   265/  269 batches | lr 0.001144 |  3.72 ms | loss 0.03764 | ppl     1.04\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  73 | time:  1.66s | valid loss 0.23012 | valid ppl     1.26\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  74 |    53/  269 batches | lr 0.001121 |  3.86 ms | loss 0.02860 | ppl     1.03\n",
      "| epoch  74 |   106/  269 batches | lr 0.001121 |  4.16 ms | loss 0.14977 | ppl     1.16\n",
      "| epoch  74 |   159/  269 batches | lr 0.001121 |  4.40 ms | loss 0.24348 | ppl     1.28\n",
      "| epoch  74 |   212/  269 batches | lr 0.001121 |  3.67 ms | loss 0.06457 | ppl     1.07\n",
      "| epoch  74 |   265/  269 batches | lr 0.001121 |  3.72 ms | loss 0.03798 | ppl     1.04\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  74 | time:  1.62s | valid loss 0.23059 | valid ppl     1.26\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  75 |    53/  269 batches | lr 0.001099 |  3.78 ms | loss 0.02890 | ppl     1.03\n",
      "| epoch  75 |   106/  269 batches | lr 0.001099 |  3.68 ms | loss 0.14833 | ppl     1.16\n",
      "| epoch  75 |   159/  269 batches | lr 0.001099 |  3.70 ms | loss 0.24403 | ppl     1.28\n",
      "| epoch  75 |   212/  269 batches | lr 0.001099 |  3.68 ms | loss 0.06584 | ppl     1.07\n",
      "| epoch  75 |   265/  269 batches | lr 0.001099 |  4.40 ms | loss 0.03764 | ppl     1.04\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  75 | time:  1.59s | valid loss 0.23072 | valid ppl     1.26\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  76 |    53/  269 batches | lr 0.001077 |  3.80 ms | loss 0.02910 | ppl     1.03\n",
      "| epoch  76 |   106/  269 batches | lr 0.001077 |  3.65 ms | loss 0.14803 | ppl     1.16\n",
      "| epoch  76 |   159/  269 batches | lr 0.001077 |  3.69 ms | loss 0.24046 | ppl     1.27\n",
      "| epoch  76 |   212/  269 batches | lr 0.001077 |  3.66 ms | loss 0.06312 | ppl     1.07\n",
      "| epoch  76 |   265/  269 batches | lr 0.001077 |  4.26 ms | loss 0.03777 | ppl     1.04\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  76 | time:  1.58s | valid loss 0.22781 | valid ppl     1.26\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  77 |    53/  269 batches | lr 0.001055 |  3.79 ms | loss 0.02769 | ppl     1.03\n",
      "| epoch  77 |   106/  269 batches | lr 0.001055 |  3.65 ms | loss 0.14901 | ppl     1.16\n",
      "| epoch  77 |   159/  269 batches | lr 0.001055 |  3.73 ms | loss 0.23429 | ppl     1.26\n",
      "| epoch  77 |   212/  269 batches | lr 0.001055 |  3.69 ms | loss 0.06357 | ppl     1.07\n",
      "| epoch  77 |   265/  269 batches | lr 0.001055 |  3.69 ms | loss 0.03833 | ppl     1.04\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  77 | time:  1.56s | valid loss 0.22538 | valid ppl     1.25\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  78 |    53/  269 batches | lr 0.001034 |  3.84 ms | loss 0.02732 | ppl     1.03\n",
      "| epoch  78 |   106/  269 batches | lr 0.001034 |  3.64 ms | loss 0.15294 | ppl     1.17\n",
      "| epoch  78 |   159/  269 batches | lr 0.001034 |  3.69 ms | loss 0.24537 | ppl     1.28\n",
      "| epoch  78 |   212/  269 batches | lr 0.001034 |  3.75 ms | loss 0.06269 | ppl     1.06\n",
      "| epoch  78 |   265/  269 batches | lr 0.001034 |  3.69 ms | loss 0.03814 | ppl     1.04\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  78 | time:  1.56s | valid loss 0.22278 | valid ppl     1.25\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  79 |    53/  269 batches | lr 0.001014 |  3.82 ms | loss 0.02571 | ppl     1.03\n",
      "| epoch  79 |   106/  269 batches | lr 0.001014 |  3.84 ms | loss 0.15138 | ppl     1.16\n",
      "| epoch  79 |   159/  269 batches | lr 0.001014 |  3.93 ms | loss 0.25005 | ppl     1.28\n",
      "| epoch  79 |   212/  269 batches | lr 0.001014 |  5.37 ms | loss 0.06763 | ppl     1.07\n",
      "| epoch  79 |   265/  269 batches | lr 0.001014 |  5.10 ms | loss 0.03709 | ppl     1.04\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  79 | time:  1.76s | valid loss 0.22879 | valid ppl     1.26\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  80 |    53/  269 batches | lr 0.000993 |  3.86 ms | loss 0.02807 | ppl     1.03\n",
      "| epoch  80 |   106/  269 batches | lr 0.000993 |  3.68 ms | loss 0.15095 | ppl     1.16\n",
      "| epoch  80 |   159/  269 batches | lr 0.000993 |  3.67 ms | loss 0.24807 | ppl     1.28\n",
      "| epoch  80 |   212/  269 batches | lr 0.000993 |  3.96 ms | loss 0.06802 | ppl     1.07\n",
      "| epoch  80 |   265/  269 batches | lr 0.000993 |  3.70 ms | loss 0.03715 | ppl     1.04\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  80 | time:  6.36s | valid loss 0.23090 | valid ppl     1.26\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  81 |    53/  269 batches | lr 0.000973 |  3.73 ms | loss 0.02925 | ppl     1.03\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arty/anaconda3/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  81 |   106/  269 batches | lr 0.000973 |  3.74 ms | loss 0.14844 | ppl     1.16\n",
      "| epoch  81 |   159/  269 batches | lr 0.000973 |  3.75 ms | loss 0.24506 | ppl     1.28\n",
      "| epoch  81 |   212/  269 batches | lr 0.000973 |  3.74 ms | loss 0.06876 | ppl     1.07\n",
      "| epoch  81 |   265/  269 batches | lr 0.000973 |  3.77 ms | loss 0.03741 | ppl     1.04\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  81 | time:  1.56s | valid loss 0.23070 | valid ppl     1.26\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  82 |    53/  269 batches | lr 0.000954 |  3.81 ms | loss 0.02920 | ppl     1.03\n",
      "| epoch  82 |   106/  269 batches | lr 0.000954 |  3.65 ms | loss 0.14741 | ppl     1.16\n",
      "| epoch  82 |   159/  269 batches | lr 0.000954 |  3.66 ms | loss 0.24309 | ppl     1.28\n",
      "| epoch  82 |   212/  269 batches | lr 0.000954 |  4.00 ms | loss 0.06815 | ppl     1.07\n",
      "| epoch  82 |   265/  269 batches | lr 0.000954 |  3.80 ms | loss 0.03748 | ppl     1.04\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  82 | time:  1.58s | valid loss 0.23085 | valid ppl     1.26\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  83 |    53/  269 batches | lr 0.000935 |  3.85 ms | loss 0.02934 | ppl     1.03\n",
      "| epoch  83 |   106/  269 batches | lr 0.000935 |  3.68 ms | loss 0.14819 | ppl     1.16\n",
      "| epoch  83 |   159/  269 batches | lr 0.000935 |  3.70 ms | loss 0.24274 | ppl     1.27\n",
      "| epoch  83 |   212/  269 batches | lr 0.000935 |  3.66 ms | loss 0.06828 | ppl     1.07\n",
      "| epoch  83 |   265/  269 batches | lr 0.000935 |  3.76 ms | loss 0.03748 | ppl     1.04\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  83 | time:  1.56s | valid loss 0.23065 | valid ppl     1.26\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  84 |    53/  269 batches | lr 0.000916 |  3.87 ms | loss 0.02882 | ppl     1.03\n",
      "| epoch  84 |   106/  269 batches | lr 0.000916 |  3.66 ms | loss 0.14666 | ppl     1.16\n",
      "| epoch  84 |   159/  269 batches | lr 0.000916 |  3.69 ms | loss 0.24196 | ppl     1.27\n",
      "| epoch  84 |   212/  269 batches | lr 0.000916 |  3.68 ms | loss 0.06931 | ppl     1.07\n",
      "| epoch  84 |   265/  269 batches | lr 0.000916 |  3.70 ms | loss 0.03734 | ppl     1.04\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  84 | time:  1.56s | valid loss 0.23089 | valid ppl     1.26\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  85 |    53/  269 batches | lr 0.000898 |  3.80 ms | loss 0.02913 | ppl     1.03\n",
      "| epoch  85 |   106/  269 batches | lr 0.000898 |  5.83 ms | loss 0.14680 | ppl     1.16\n",
      "| epoch  85 |   159/  269 batches | lr 0.000898 |  5.67 ms | loss 0.24176 | ppl     1.27\n",
      "| epoch  85 |   212/  269 batches | lr 0.000898 |  5.97 ms | loss 0.07011 | ppl     1.07\n",
      "| epoch  85 |   265/  269 batches | lr 0.000898 |  4.65 ms | loss 0.03750 | ppl     1.04\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  85 | time:  1.95s | valid loss 0.23104 | valid ppl     1.26\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  86 |    53/  269 batches | lr 0.000880 |  3.82 ms | loss 0.02938 | ppl     1.03\n",
      "| epoch  86 |   106/  269 batches | lr 0.000880 |  3.76 ms | loss 0.14754 | ppl     1.16\n",
      "| epoch  86 |   159/  269 batches | lr 0.000880 |  3.78 ms | loss 0.24195 | ppl     1.27\n",
      "| epoch  86 |   212/  269 batches | lr 0.000880 |  3.75 ms | loss 0.07061 | ppl     1.07\n",
      "| epoch  86 |   265/  269 batches | lr 0.000880 |  3.70 ms | loss 0.03750 | ppl     1.04\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  86 | time:  1.57s | valid loss 0.23117 | valid ppl     1.26\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  87 |    53/  269 batches | lr 0.000862 |  4.02 ms | loss 0.02915 | ppl     1.03\n",
      "| epoch  87 |   106/  269 batches | lr 0.000862 |  3.80 ms | loss 0.14623 | ppl     1.16\n",
      "| epoch  87 |   159/  269 batches | lr 0.000862 |  4.69 ms | loss 0.24139 | ppl     1.27\n",
      "| epoch  87 |   212/  269 batches | lr 0.000862 |  4.03 ms | loss 0.07039 | ppl     1.07\n",
      "| epoch  87 |   265/  269 batches | lr 0.000862 |  3.79 ms | loss 0.03760 | ppl     1.04\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  87 | time:  1.65s | valid loss 0.23124 | valid ppl     1.26\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  88 |    53/  269 batches | lr 0.000845 |  3.88 ms | loss 0.02922 | ppl     1.03\n",
      "| epoch  88 |   106/  269 batches | lr 0.000845 |  3.66 ms | loss 0.14498 | ppl     1.16\n",
      "| epoch  88 |   159/  269 batches | lr 0.000845 |  3.74 ms | loss 0.24081 | ppl     1.27\n",
      "| epoch  88 |   212/  269 batches | lr 0.000845 |  4.10 ms | loss 0.07037 | ppl     1.07\n",
      "| epoch  88 |   265/  269 batches | lr 0.000845 |  4.03 ms | loss 0.03755 | ppl     1.04\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  88 | time:  1.61s | valid loss 0.23097 | valid ppl     1.26\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  89 |    53/  269 batches | lr 0.000828 |  3.86 ms | loss 0.02898 | ppl     1.03\n",
      "| epoch  89 |   106/  269 batches | lr 0.000828 |  3.72 ms | loss 0.14505 | ppl     1.16\n",
      "| epoch  89 |   159/  269 batches | lr 0.000828 |  4.11 ms | loss 0.24117 | ppl     1.27\n",
      "| epoch  89 |   212/  269 batches | lr 0.000828 |  3.71 ms | loss 0.07040 | ppl     1.07\n",
      "| epoch  89 |   265/  269 batches | lr 0.000828 |  4.14 ms | loss 0.03759 | ppl     1.04\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  89 | time:  1.63s | valid loss 0.23109 | valid ppl     1.26\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  90 |    53/  269 batches | lr 0.000812 |  3.84 ms | loss 0.02898 | ppl     1.03\n",
      "| epoch  90 |   106/  269 batches | lr 0.000812 |  4.54 ms | loss 0.14545 | ppl     1.16\n",
      "| epoch  90 |   159/  269 batches | lr 0.000812 |  4.36 ms | loss 0.24251 | ppl     1.27\n",
      "| epoch  90 |   212/  269 batches | lr 0.000812 |  3.69 ms | loss 0.06964 | ppl     1.07\n",
      "| epoch  90 |   265/  269 batches | lr 0.000812 |  4.08 ms | loss 0.03749 | ppl     1.04\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  90 | time:  6.81s | valid loss 0.22949 | valid ppl     1.26\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arty/anaconda3/lib/python3.9/site-packages/torch/optim/lr_scheduler.py:369: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch  91 |    53/  269 batches | lr 0.000795 |  3.82 ms | loss 0.02823 | ppl     1.03\n",
      "| epoch  91 |   106/  269 batches | lr 0.000795 |  3.70 ms | loss 0.14729 | ppl     1.16\n",
      "| epoch  91 |   159/  269 batches | lr 0.000795 |  5.00 ms | loss 0.24406 | ppl     1.28\n",
      "| epoch  91 |   212/  269 batches | lr 0.000795 |  3.82 ms | loss 0.06930 | ppl     1.07\n",
      "| epoch  91 |   265/  269 batches | lr 0.000795 |  3.84 ms | loss 0.03751 | ppl     1.04\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  91 | time:  1.64s | valid loss 0.22976 | valid ppl     1.26\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  92 |    53/  269 batches | lr 0.000779 |  3.89 ms | loss 0.02850 | ppl     1.03\n",
      "| epoch  92 |   106/  269 batches | lr 0.000779 |  3.71 ms | loss 0.14745 | ppl     1.16\n",
      "| epoch  92 |   159/  269 batches | lr 0.000779 |  3.78 ms | loss 0.24455 | ppl     1.28\n",
      "| epoch  92 |   212/  269 batches | lr 0.000779 |  3.75 ms | loss 0.06884 | ppl     1.07\n",
      "| epoch  92 |   265/  269 batches | lr 0.000779 |  3.83 ms | loss 0.03746 | ppl     1.04\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  92 | time:  1.58s | valid loss 0.22963 | valid ppl     1.26\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  93 |    53/  269 batches | lr 0.000764 |  3.86 ms | loss 0.02821 | ppl     1.03\n",
      "| epoch  93 |   106/  269 batches | lr 0.000764 |  3.75 ms | loss 0.14637 | ppl     1.16\n",
      "| epoch  93 |   159/  269 batches | lr 0.000764 |  3.71 ms | loss 0.24433 | ppl     1.28\n",
      "| epoch  93 |   212/  269 batches | lr 0.000764 |  3.68 ms | loss 0.06878 | ppl     1.07\n",
      "| epoch  93 |   265/  269 batches | lr 0.000764 |  3.73 ms | loss 0.03757 | ppl     1.04\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  93 | time:  1.57s | valid loss 0.22899 | valid ppl     1.26\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  94 |    53/  269 batches | lr 0.000749 |  3.82 ms | loss 0.02822 | ppl     1.03\n",
      "| epoch  94 |   106/  269 batches | lr 0.000749 |  3.66 ms | loss 0.14594 | ppl     1.16\n",
      "| epoch  94 |   159/  269 batches | lr 0.000749 |  3.96 ms | loss 0.24499 | ppl     1.28\n",
      "| epoch  94 |   212/  269 batches | lr 0.000749 |  4.43 ms | loss 0.06815 | ppl     1.07\n",
      "| epoch  94 |   265/  269 batches | lr 0.000749 |  3.97 ms | loss 0.03776 | ppl     1.04\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  94 | time:  1.63s | valid loss 0.22795 | valid ppl     1.26\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  95 |    53/  269 batches | lr 0.000734 |  3.88 ms | loss 0.02769 | ppl     1.03\n",
      "| epoch  95 |   106/  269 batches | lr 0.000734 |  3.67 ms | loss 0.14670 | ppl     1.16\n",
      "| epoch  95 |   159/  269 batches | lr 0.000734 |  3.81 ms | loss 0.24626 | ppl     1.28\n",
      "| epoch  95 |   212/  269 batches | lr 0.000734 |  3.67 ms | loss 0.06768 | ppl     1.07\n",
      "| epoch  95 |   265/  269 batches | lr 0.000734 |  4.17 ms | loss 0.03795 | ppl     1.04\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  95 | time:  1.59s | valid loss 0.22620 | valid ppl     1.25\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  96 |    53/  269 batches | lr 0.000719 |  3.84 ms | loss 0.02706 | ppl     1.03\n",
      "| epoch  96 |   106/  269 batches | lr 0.000719 |  3.73 ms | loss 0.14710 | ppl     1.16\n",
      "| epoch  96 |   159/  269 batches | lr 0.000719 |  3.73 ms | loss 0.24749 | ppl     1.28\n",
      "| epoch  96 |   212/  269 batches | lr 0.000719 |  3.81 ms | loss 0.06713 | ppl     1.07\n",
      "| epoch  96 |   265/  269 batches | lr 0.000719 |  3.71 ms | loss 0.03825 | ppl     1.04\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  96 | time:  1.57s | valid loss 0.22487 | valid ppl     1.25\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  97 |    53/  269 batches | lr 0.000705 |  3.90 ms | loss 0.02678 | ppl     1.03\n",
      "| epoch  97 |   106/  269 batches | lr 0.000705 |  3.64 ms | loss 0.14727 | ppl     1.16\n",
      "| epoch  97 |   159/  269 batches | lr 0.000705 |  4.78 ms | loss 0.24834 | ppl     1.28\n",
      "| epoch  97 |   212/  269 batches | lr 0.000705 |  5.86 ms | loss 0.06650 | ppl     1.07\n",
      "| epoch  97 |   265/  269 batches | lr 0.000705 |  4.92 ms | loss 0.03866 | ppl     1.04\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  97 | time:  1.79s | valid loss 0.22251 | valid ppl     1.25\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  98 |    53/  269 batches | lr 0.000690 |  4.23 ms | loss 0.02585 | ppl     1.03\n",
      "| epoch  98 |   106/  269 batches | lr 0.000690 |  3.75 ms | loss 0.14839 | ppl     1.16\n",
      "| epoch  98 |   159/  269 batches | lr 0.000690 |  3.73 ms | loss 0.25042 | ppl     1.28\n",
      "| epoch  98 |   212/  269 batches | lr 0.000690 |  3.79 ms | loss 0.06581 | ppl     1.07\n",
      "| epoch  98 |   265/  269 batches | lr 0.000690 |  3.80 ms | loss 0.03872 | ppl     1.04\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  98 | time:  1.60s | valid loss 0.22203 | valid ppl     1.25\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch  99 |    53/  269 batches | lr 0.000677 |  3.92 ms | loss 0.02573 | ppl     1.03\n",
      "| epoch  99 |   106/  269 batches | lr 0.000677 |  3.76 ms | loss 0.14821 | ppl     1.16\n",
      "| epoch  99 |   159/  269 batches | lr 0.000677 |  3.75 ms | loss 0.25097 | ppl     1.29\n",
      "| epoch  99 |   212/  269 batches | lr 0.000677 |  3.78 ms | loss 0.06519 | ppl     1.07\n",
      "| epoch  99 |   265/  269 batches | lr 0.000677 |  3.77 ms | loss 0.03871 | ppl     1.04\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch  99 | time:  1.58s | valid loss 0.22169 | valid ppl     1.25\n",
      "-----------------------------------------------------------------------------------------\n",
      "| epoch 100 |    53/  269 batches | lr 0.000663 |  3.87 ms | loss 0.02576 | ppl     1.03\n",
      "| epoch 100 |   106/  269 batches | lr 0.000663 |  3.68 ms | loss 0.14878 | ppl     1.16\n",
      "| epoch 100 |   159/  269 batches | lr 0.000663 |  3.68 ms | loss 0.25179 | ppl     1.29\n",
      "| epoch 100 |   212/  269 batches | lr 0.000663 |  3.73 ms | loss 0.06469 | ppl     1.07\n",
      "| epoch 100 |   265/  269 batches | lr 0.000663 |  4.44 ms | loss 0.03848 | ppl     1.04\n",
      "-----------------------------------------------------------------------------------------\n",
      "| end of epoch 100 | time:  6.68s | valid loss 0.22169 | valid ppl     1.25\n",
      "-----------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "def evaluate(eval_model, data_source):\n",
    "    eval_model.eval() \n",
    "    total_loss = 0.\n",
    "    eval_batch_size = 200\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, len(data_source) - 1, eval_batch_size):\n",
    "            data, targets = get_batch(data_source, i,eval_batch_size)\n",
    "            output = eval_model(data)            \n",
    "            if calculate_loss_over_all_values:\n",
    "                total_loss += len(data[0])* criterion(output, targets).cpu().item()\n",
    "            else:                                \n",
    "                total_loss += len(data[0])* criterion(output[-output_window:], targets[-output_window:]).cpu().item()            \n",
    "    return total_loss / len(data_source)\n",
    "\n",
    "train_data, val_data = get_data()\n",
    "model = TransAm().to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "lr = 0.005 \n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1.0, gamma=0.98)\n",
    "\n",
    "best_val_loss = float(\"inf\")\n",
    "epochs = 100 \n",
    "\n",
    "for epoch in range(1, epochs + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    train(train_data)\n",
    "    \n",
    "    if(epoch % 10 is 0):\n",
    "        val_loss = plot_and_loss(model, val_data,epoch)\n",
    "        predict_future(model, val_data,200)\n",
    "    else:\n",
    "        val_loss = evaluate(model, val_data)\n",
    "        \n",
    "    print('-' * 89)\n",
    "    print('| end of epoch {:3d} | time: {:5.2f}s | valid loss {:5.5f} | valid ppl {:8.2f}'.format(epoch, (time.time() - epoch_start_time),\n",
    "                                     val_loss, math.exp(val_loss)))\n",
    "    print('-' * 89)\n",
    "\n",
    "    scheduler.step() \n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "bccc0f41f7f3bcaeffddd9741ddcda1f7d088846fa513f73350e28c16010e459"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
